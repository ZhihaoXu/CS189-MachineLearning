{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example of gradient checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gradient checking: compare the analytical gradient with the numerical gradient\n",
    "# taking the affine layer as an example\n",
    "from gradient_check import eval_numerical_gradient_array\n",
    "import numpy as np\n",
    "from layers import *\n",
    "N = 2\n",
    "D = 3\n",
    "M = 4\n",
    "x = np.random.normal(size=(N, D))\n",
    "w = np.random.normal(size=(D, M))\n",
    "b = np.random.normal(size=(M, ))\n",
    "dout = np.random.normal(size=(N, M))\n",
    "\n",
    "# do a forward pass first\n",
    "out, cache = affine_forward(x, w, b)\n",
    "# check grad f/grad w, the [0] below gets the output out of the (output, cache) original output\n",
    "f=lambda w: affine_forward(x, w, b)[0]\n",
    "# compute the analytical gradient you wrote, [1] get the dw out of the (dx, dw, db) original output\n",
    "grad = affine_backward(dout, cache)[1]\n",
    "# compute the numerical gradient using the provided utility function\n",
    "ngrad = eval_numerical_gradient_array(f, w, dout)\n",
    "print(grad)\n",
    "print(ngrad)\n",
    "# they should be similar enough within some small error tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example of training a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "data = scipy.io.loadmat(\"mnist_data.mat\")\n",
    "X = data['training_data']\n",
    "y = data['training_labels'].ravel()\n",
    "X_test = data['test_data']\n",
    "\n",
    "# Split the data into a training set and validation set.\n",
    "num_train = X.shape[0]\n",
    "indices = np.array(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[0:50000], indices[50000:]\n",
    "X_train, X_val = X[train_indices], X[val_indices]\n",
    "y_train, y_val = y[train_indices], y[val_indices]\n",
    "\n",
    "from solver import Solver\n",
    "from classifiers.fc_net import FullyConnectedNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "      'X_train': X_train,\n",
    "      'y_train': y_train,\n",
    "      'X_val': X_val,\n",
    "      'y_val': y_val}\n",
    "\n",
    "# TODO: fill out the hyperparamets\n",
    "hyperparams = {'lr_decay': ,\n",
    "               'num_epochs': ,\n",
    "               'batch_size': ,\n",
    "               'learning_rate': \n",
    "              }\n",
    "\n",
    "# TODO: fill out the number of units in your hidden layers\n",
    "hidden_dim = [] # this should be a list of units for each hiddent layer\n",
    "\n",
    "model = FullyConnectedNet(input_dim=784,\n",
    "                          hidden_dim=hidden_dim)\n",
    "solver = Solver(model, data,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                  'learning_rate': hyperparams['learning_rate'],\n",
    "                },\n",
    "                lr_decay=hyperparams['lr_decay'],\n",
    "                num_epochs=hyperparams['num_epochs'], \n",
    "                batch_size=hyperparams['batch_size'],\n",
    "                print_every=100)\n",
    "solver.train()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
